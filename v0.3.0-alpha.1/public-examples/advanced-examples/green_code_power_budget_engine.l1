// Green Code: Power Budget Constraint - Edge Device Power Management
// Real-world application for ultra-low power AI deployment

println("=== GREEN CODE: Power Budget Constraint Engine ===");
println("Manages power consumption for edge AI deployment under 1W constraint");

function analyze_edge_device_power_budget(device_type, baseline_power_watts) {
    let power_analysis = "";
    
    // Device power breakdown
    let cpu_power = baseline_power_watts * 0.4;
    let memory_power = baseline_power_watts * 0.3;
    let peripheral_power = baseline_power_watts * 0.2;
    let idle_power = baseline_power_watts * 0.1;
    
    power_analysis = power_analysis + device_type + " Power Breakdown:\n";
    power_analysis = power_analysis + "  CPU: " + to_string(round(cpu_power)) + "W\n";
    power_analysis = power_analysis + "  Memory: " + to_string(round(memory_power)) + "W\n";
    power_analysis = power_analysis + "  Peripherals: " + to_string(round(peripheral_power)) + "W\n";
    power_analysis = power_analysis + "  Idle: " + to_string(round(idle_power)) + "W\n";
    power_analysis = power_analysis + "  Total: " + to_string(round(baseline_power_watts)) + "W\n";
    
    return power_analysis;
}

function calculate_llm_power_allocation(total_budget_watts, inference_frequency_hz) {
    let power_allocation = "";
    
    // Power allocation strategy
    let cpu_llm_budget = total_budget_watts * 0.6; // 60% for LLM inference
    let memory_llm_budget = total_budget_watts * 0.25; // 25% for memory operations
    let system_overhead = total_budget_watts * 0.15; // 15% for system operations
    
    // Calculate per-inference power
    let inference_interval_ms = 1000.0 / inference_frequency_hz;
    let power_per_inference = (cpu_llm_budget + memory_llm_budget) / inference_frequency_hz;
    
    power_allocation = power_allocation + "Power Budget Allocation:\n";
    power_allocation = power_allocation + "  CPU LLM: " + to_string(round(cpu_llm_budget)) + "W\n";
    power_allocation = power_allocation + "  Memory LLM: " + to_string(round(memory_llm_budget)) + "W\n";
    power_allocation = power_allocation + "  System overhead: " + to_string(round(system_overhead)) + "W\n";
    power_allocation = power_allocation + "  Power per inference: " + to_string(round(power_per_inference)) + "W\n";
    power_allocation = power_allocation + "  Inference interval: " + to_string(round(inference_interval_ms)) + "ms\n";
    
    return power_allocation;
}

function optimize_for_power_constraint(model_complexity, target_power_watts, max_latency_ms) {
    let optimization_strategy = "";
    let current_power = model_complexity * 0.05; // 50mW per complexity unit
    let current_latency = model_complexity * 0.1; // 0.1ms per complexity unit
    
    optimization_strategy = optimization_strategy + "Initial: " + to_string(round(current_power)) + "W, " + to_string(round(current_latency)) + "ms\n";
    
    // Optimization step 1: Quantization
    current_power = current_power * 0.4; // 60% power reduction
    current_latency = current_latency * 0.8; // 20% latency improvement
    optimization_strategy = optimization_strategy + "After quantization: " + to_string(round(current_power)) + "W, " + to_string(round(current_latency)) + "ms\n";
    
    // Optimization step 2: Pruning
    current_power = current_power * 0.6; // Additional 40% power reduction
    current_latency = current_latency * 0.9; // 10% latency improvement
    optimization_strategy = optimization_strategy + "After pruning: " + to_string(round(current_power)) + "W, " + to_string(round(current_latency)) + "ms\n";
    
    // Optimization step 3: Kernel optimization
    current_power = current_power * 0.7; // Additional 30% power reduction
    current_latency = current_latency * 0.8; // 20% latency improvement
    optimization_strategy = optimization_strategy + "After kernel optimization: " + to_string(round(current_power)) + "W, " + to_string(round(current_latency)) + "ms\n";
    
    let feasibility = "";
    if (current_power <= target_power_watts && current_latency <= max_latency_ms) {
        feasibility = "✅ FEASIBLE - Meets all constraints";
    } else if (current_power <= target_power_watts) {
        feasibility = "⚠️ POWER OK - Latency exceeds target";
    } else if (current_latency <= max_latency_ms) {
        feasibility = "⚠️ LATENCY OK - Power exceeds budget";
    } else {
        feasibility = "❌ NOT FEASIBLE - Both constraints exceeded";
    }
    
    return optimization_strategy + "Result: " + feasibility;
}

function calculate_thermal_impact(power_watts, thermal_resistance_c_per_watt) {
    let temperature_rise = power_watts * thermal_resistance_c_per_watt;
    let ambient_temp = 25.0; // 25°C ambient
    let junction_temp = ambient_temp + temperature_rise;
    
    let thermal_status = "";
    if (junction_temp <= 70.0) {
        thermal_status = "Safe - No thermal throttling needed";
    } else if (junction_temp <= 85.0) {
        thermal_status = "Warning - Consider thermal management";
    } else if (junction_temp <= 100.0) {
        thermal_status = "Critical - Thermal throttling required";
    } else {
        thermal_status = "Dangerous - Thermal shutdown imminent";
    }
    
    return "Temperature rise: " + to_string(round(temperature_rise)) + "°C, " +
           "Junction temperature: " + to_string(round(junction_temp)) + "°C - " + thermal_status;
}

function simulate_power_scaling(model_variants, power_constraint_watts) {
    let scaling_analysis = "";
    let feasible_variants = 0;
    
    let i = 0;
    while (i < len(model_variants)) {
        let variant_power = model_variants[i];
        let variant_name = "";
        
        if (i == 0) variant_name = "Full model";
        else if (i == 1) variant_name = "Quantized model";
        else if (i == 2) variant_name = "Pruned model";
        else if (i == 3) variant_name = "Distilled model";
        else variant_name = "Ultra-compact model";
        
        let feasibility = "";
        if (variant_power <= power_constraint_watts) {
            feasibility = "✅ Feasible";
            feasible_variants = feasible_variants + 1;
        } else {
            feasibility = "❌ Exceeds budget";
        }
        
        let efficiency = variant_power / power_constraint_watts * 100.0;
        scaling_analysis = scaling_analysis + variant_name + ": " + to_string(round(variant_power)) + "W (" + 
                         to_string(round(efficiency)) + "% of budget) - " + feasibility + "\n";
        
        i = i + 1;
    }
    
    return scaling_analysis + "Feasible variants: " + to_string(feasible_variants) + "/" + to_string(len(model_variants));
}

// Test scenarios
println("");
println("=== SCENARIO 1: Raspberry Pi Power Analysis ===");
let rpi_power_analysis = analyze_edge_device_power_budget("Raspberry Pi 4", 3.0);
println(rpi_power_analysis);

println("");
println("=== SCENARIO 2: Ultra-Low Power IoT Device ===");
let iot_power_analysis = analyze_edge_device_power_budget("IoT Device", 0.5);
println(iot_power_analysis);

println("");
println("=== SCENARIO 3: LLM Power Allocation ===");
let llm_allocation = calculate_llm_power_allocation(1.0, 10.0); // 1W total, 10Hz inference
println("Total budget: 1W, Inference frequency: 10Hz");
println(llm_allocation);

println("");
println("=== SCENARIO 4: Power Constraint Optimization ===");
let constraint_optimization = optimize_for_power_constraint(200.0, 0.5, 50.0);
println("Model complexity: 200, Target power: 0.5W, Max latency: 50ms");
println(constraint_optimization);

println("");
println("=== SCENARIO 5: Thermal Analysis ===");
let thermal_analysis = calculate_thermal_impact(0.8, 15.0);
println("Power: 0.8W, Thermal resistance: 15°C/W");
println(thermal_analysis);

println("");
println("=== SCENARIO 6: Power Scaling Analysis ===");
let model_variants = [3.0, 1.5, 0.8, 0.4, 0.2]; // Different model variants
let scaling_analysis = simulate_power_scaling(model_variants, 1.0);
println("Power constraint: 1W");
println(scaling_analysis);

println("");
println("=== SCENARIO 7: Edge AI Power Budget ===");
let edge_ai_allocation = calculate_llm_power_allocation(0.8, 5.0); // 0.8W total, 5Hz inference
println("Edge AI device: 0.8W total budget, 5Hz inference");
println(edge_ai_allocation);

println("");
println("✅ Power budget analysis completed successfully!");
